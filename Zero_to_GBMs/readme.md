### "Machine Learning with Python: Zero to GBMs"

This is a practical and beginner-friendly introduction to supervised machine learning, decision trees, and gradient boosting using Python. These tutorials take a practical and coding-focused approach. The best way to learn the material is to execute the code and experiment with it.Check out the full series here: 




1. [Lesson 1 - Linear Regression with Scikit Learn](https://github.com/SoundaryaMiranam/Machine_learning_lessons/blob/main/Zero_to_GBMs/lesson_1_Linear_Regression.ipynb)
   
   <ul>
     <li>Preparing data for machine learning</li>
     <li>Linear regression with multiple features</li>
    <li>Generating predictions and evaluating models</li>
  </ul>  

2. [Lesson 2 - Logistic Regression for Classification](https://github.com/SoundaryaMiranam/Machine_learning_lessons/blob/main/Zero_to_GBMs/lesson_2_logistic_regression.ipynb)
    <ul>
     <li>Downloading & processing Kaggle datasets</li>
     <li>Training a logistic regression model</li>
    <li>Model evaluation, prediction & persistence</li>
   </ul>  
   
3. [Lesson 3 - Decision Trees and Hyperparameters](https://github.com/SoundaryaMiranam/Machine_learning_lessons/blob/main/Zero_to_GBMs/lesson_3_Decision_Trees_and_regularlization.ipynb)
    <ul>
     <li>Downloading a real-world dataset</li>
     <li>Preparing a dataset for training</li>
    <li>Training & interpreting decision trees</li>
   </ul>  
   
4. [Lesson 4 - Random Forests and Regularization](https://github.com/SoundaryaMiranam/Machine_learning_lessons/blob/main/Zero_to_GBMs/lesson_4_Random_Forests_and_Regularization.ipynb)
   <ul>
     <li>Training and interpreting random forests</li>
      <li>Ensemble methods and random forests</li>
     <li>Hyperparameter tuning and regularization</li>
   </ul> 
5. [Lesson 5 - Gradient Boosting with XGBoost]()
6. [Lesson 6 - Unsupervised Learning and Recommendations]()
7. [Course Project - Real-World Machine Learning Model]()
